{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1319405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "Pandas version: 2.1.4\n",
      "NumPy version: 1.26.2\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd4a7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 CSV files:\n",
      "\n",
      "  - olist_sellers_dataset.csv\n",
      "  - product_category_name_translation.csv\n",
      "  - olist_orders_dataset.csv\n",
      "  - olist_order_items_dataset.csv\n",
      "  - olist_customers_dataset.csv\n",
      "  - olist_geolocation_dataset.csv\n",
      "  - olist_order_payments_dataset.csv\n",
      "  - olist_order_reviews_dataset.csv\n",
      "  - olist_products_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Define data path\n",
    "raw_data_path = Path('../data/raw')\n",
    "\n",
    "# List all CSV files\n",
    "csv_files = list(raw_data_path.glob('*.csv'))\n",
    "print(f\"Found {len(csv_files)} CSV files:\\n\")\n",
    "for file in csv_files:\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb39a8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n",
      "‚úÖ Orders: 99,441 rows √ó 8 columns\n",
      "‚úÖ Order Items: 112,650 rows √ó 7 columns\n",
      "‚úÖ Products: 32,951 rows √ó 9 columns\n",
      "‚úÖ Customers: 99,441 rows √ó 5 columns\n",
      "‚úÖ Sellers: 3,095 rows √ó 4 columns\n",
      "‚úÖ Payments: 103,886 rows √ó 5 columns\n",
      "‚úÖ Reviews: 99,224 rows √ó 7 columns\n",
      "‚úÖ Geolocation: 1,000,163 rows √ó 5 columns\n",
      "‚úÖ Category Translation: 71 rows √ó 2 columns\n",
      "\n",
      "üéâ Total records across all datasets: 1,550,851\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "print(\"Loading datasets...\\n\")\n",
    "\n",
    "# Orders\n",
    "orders = pd.read_csv(raw_data_path / 'olist_orders_dataset.csv')\n",
    "print(f\"‚úÖ Orders: {orders.shape[0]:,} rows √ó {orders.shape[1]} columns\")\n",
    "\n",
    "# Order Items\n",
    "order_items = pd.read_csv(raw_data_path / 'olist_order_items_dataset.csv')\n",
    "print(f\"‚úÖ Order Items: {order_items.shape[0]:,} rows √ó {order_items.shape[1]} columns\")\n",
    "\n",
    "# Products\n",
    "products = pd.read_csv(raw_data_path / 'olist_products_dataset.csv')\n",
    "print(f\"‚úÖ Products: {products.shape[0]:,} rows √ó {products.shape[1]} columns\")\n",
    "\n",
    "# Customers\n",
    "customers = pd.read_csv(raw_data_path / 'olist_customers_dataset.csv')\n",
    "print(f\"‚úÖ Customers: {customers.shape[0]:,} rows √ó {customers.shape[1]} columns\")\n",
    "\n",
    "# Sellers\n",
    "sellers = pd.read_csv(raw_data_path / 'olist_sellers_dataset.csv')\n",
    "print(f\"‚úÖ Sellers: {sellers.shape[0]:,} rows √ó {sellers.shape[1]} columns\")\n",
    "\n",
    "# Payments\n",
    "payments = pd.read_csv(raw_data_path / 'olist_order_payments_dataset.csv')\n",
    "print(f\"‚úÖ Payments: {payments.shape[0]:,} rows √ó {payments.shape[1]} columns\")\n",
    "\n",
    "# Reviews\n",
    "reviews = pd.read_csv(raw_data_path / 'olist_order_reviews_dataset.csv')\n",
    "print(f\"‚úÖ Reviews: {reviews.shape[0]:,} rows √ó {reviews.shape[1]} columns\")\n",
    "\n",
    "# Geolocation\n",
    "geolocation = pd.read_csv(raw_data_path / 'olist_geolocation_dataset.csv')\n",
    "print(f\"‚úÖ Geolocation: {geolocation.shape[0]:,} rows √ó {geolocation.shape[1]} columns\")\n",
    "\n",
    "# Category translation\n",
    "category_translation = pd.read_csv(raw_data_path / 'product_category_name_translation.csv')\n",
    "print(f\"‚úÖ Category Translation: {category_translation.shape[0]:,} rows √ó {category_translation.shape[1]} columns\")\n",
    "\n",
    "print(f\"\\nüéâ Total records across all datasets: {orders.shape[0] + order_items.shape[0] + products.shape[0] + customers.shape[0] + sellers.shape[0] + payments.shape[0] + reviews.shape[0] + geolocation.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6be7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ORDERS DATASET - DETAILED INSPECTION\n",
      "================================================================================\n",
      "\n",
      "üìä Column names and types:\n",
      "order_id                         object\n",
      "customer_id                      object\n",
      "order_status                     object\n",
      "order_purchase_timestamp         object\n",
      "order_approved_at                object\n",
      "order_delivered_carrier_date     object\n",
      "order_delivered_customer_date    object\n",
      "order_estimated_delivery_date    object\n",
      "dtype: object\n",
      "\n",
      "üìã First 3 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Missing values:\n",
      "order_approved_at                 160\n",
      "order_delivered_carrier_date     1783\n",
      "order_delivered_customer_date    2965\n",
      "dtype: int64\n",
      "\n",
      "üìà Basic statistics:\n",
      "                                order_id                       customer_id  \\\n",
      "count                              99441                             99441   \n",
      "unique                             99441                             99441   \n",
      "top     e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "freq                                   1                                 1   \n",
      "\n",
      "       order_status order_purchase_timestamp    order_approved_at  \\\n",
      "count         99441                    99441                99281   \n",
      "unique            8                    98875                90733   \n",
      "top       delivered      2018-04-11 10:48:14  2018-02-27 04:31:10   \n",
      "freq          96478                        3                    9   \n",
      "\n",
      "       order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "count                         97658                         96476   \n",
      "unique                        81018                         95664   \n",
      "top             2018-05-09 15:48:00           2018-05-08 23:38:46   \n",
      "freq                             47                             3   \n",
      "\n",
      "       order_estimated_delivery_date  \n",
      "count                          99441  \n",
      "unique                           459  \n",
      "top              2017-12-20 00:00:00  \n",
      "freq                             522  \n"
     ]
    }
   ],
   "source": [
    "# Detailed look at the main Orders dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"ORDERS DATASET - DETAILED INSPECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Column names and types:\")\n",
    "print(orders.dtypes)\n",
    "\n",
    "print(\"\\nüìã First 3 rows:\")\n",
    "display(orders.head(3))\n",
    "\n",
    "print(\"\\n‚ùì Missing values:\")\n",
    "missing = orders.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "\n",
    "print(\"\\nüìà Basic statistics:\")\n",
    "print(orders.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d6c229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ DATE RANGE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä Data covers from 2016-09-04 to 2018-10-17\n",
      "üìä Total duration: 772 days (2.1 years)\n",
      "\n",
      "üìà Orders per month:\n",
      "year_month  order_count\n",
      "   2016-09            4\n",
      "   2016-10          324\n",
      "   2016-12            1\n",
      "   2017-01          800\n",
      "   2017-02         1780\n",
      "   2017-03         2682\n",
      "   2017-04         2404\n",
      "   2017-05         3700\n",
      "   2017-06         3245\n",
      "   2017-07         4026\n",
      "   2017-08         4331\n",
      "   2017-09         4285\n",
      "   2017-10         4631\n",
      "   2017-11         7544\n",
      "   2017-12         5673\n",
      "   2018-01         7269\n",
      "   2018-02         6728\n",
      "   2018-03         7211\n",
      "   2018-04         6939\n",
      "   2018-05         6873\n",
      "   2018-06         6167\n",
      "   2018-07         6292\n",
      "   2018-08         6512\n",
      "   2018-09           16\n",
      "   2018-10            4\n",
      "\n",
      "üî• Peak month: 2017-11 with 7,544 orders\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATE RANGE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üìÖ DATE RANGE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Convert date columns to datetime\n",
    "orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'])\n",
    "orders['order_approved_at'] = pd.to_datetime(orders['order_approved_at'])\n",
    "orders['order_delivered_customer_date'] = pd.to_datetime(orders['order_delivered_customer_date'])\n",
    "orders['order_estimated_delivery_date'] = pd.to_datetime(orders['order_estimated_delivery_date'])\n",
    "\n",
    "# Find date range\n",
    "min_date = orders['order_purchase_timestamp'].min()\n",
    "max_date = orders['order_purchase_timestamp'].max()\n",
    "date_range_days = (max_date - min_date).days\n",
    "\n",
    "print(f\"\\nüìä Data covers from {min_date.date()} to {max_date.date()}\")\n",
    "print(f\"üìä Total duration: {date_range_days} days ({date_range_days/365:.1f} years)\")\n",
    "\n",
    "# Orders by year-month\n",
    "orders['year_month'] = orders['order_purchase_timestamp'].dt.to_period('M')\n",
    "orders_by_month = orders.groupby('year_month').size().reset_index(name='order_count')\n",
    "\n",
    "print(f\"\\nüìà Orders per month:\")\n",
    "print(orders_by_month.to_string(index=False))\n",
    "\n",
    "# Peak month\n",
    "peak_month = orders_by_month.loc[orders_by_month['order_count'].idxmax()]\n",
    "print(f\"\\nüî• Peak month: {peak_month['year_month']} with {peak_month['order_count']:,} orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "763fd1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ ORDER STATUS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä Order Status Distribution:\n",
      "  delivered           : 96,478 (97.02%)\n",
      "  shipped             :  1,107 ( 1.11%)\n",
      "  canceled            :    625 ( 0.63%)\n",
      "  unavailable         :    609 ( 0.61%)\n",
      "  invoiced            :    314 ( 0.32%)\n",
      "  processing          :    301 ( 0.30%)\n",
      "  created             :      5 ( 0.01%)\n",
      "  approved            :      2 ( 0.00%)\n",
      "\n",
      "üöö Delivery Performance (for 96,478 delivered orders):\n",
      "  Average delivery time: 12.1 days\n",
      "  Median delivery time:  10.0 days\n",
      "  Min delivery time:     0.0 days\n",
      "  Max delivery time:     209.0 days\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ORDER STATUS ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüì¶ ORDER STATUS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Order status distribution\n",
    "status_counts = orders['order_status'].value_counts()\n",
    "status_pct = orders['order_status'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nüìä Order Status Distribution:\")\n",
    "for status, count in status_counts.items():\n",
    "    pct = status_pct[status]\n",
    "    print(f\"  {status:20s}: {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "# Calculate delivery performance\n",
    "delivered_orders = orders[orders['order_status'] == 'delivered'].copy()\n",
    "delivered_orders['delivery_time'] = (\n",
    "    delivered_orders['order_delivered_customer_date'] - \n",
    "    delivered_orders['order_purchase_timestamp']\n",
    ").dt.days\n",
    "\n",
    "print(f\"\\nüöö Delivery Performance (for {len(delivered_orders):,} delivered orders):\")\n",
    "print(f\"  Average delivery time: {delivered_orders['delivery_time'].mean():.1f} days\")\n",
    "print(f\"  Median delivery time:  {delivered_orders['delivery_time'].median():.1f} days\")\n",
    "print(f\"  Min delivery time:     {delivered_orders['delivery_time'].min():.1f} days\")\n",
    "print(f\"  Max delivery time:     {delivered_orders['delivery_time'].max():.1f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddc75f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè∑Ô∏è PRODUCT CATEGORIES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä Top 15 Product Categories by Product Count:\n",
      "   1. bed_bath_table                : 3,029 products\n",
      "   2. sports_leisure                : 2,867 products\n",
      "   3. furniture_decor               : 2,657 products\n",
      "   4. health_beauty                 : 2,444 products\n",
      "   5. housewares                    : 2,335 products\n",
      "   6. auto                          : 1,900 products\n",
      "   7. computers_accessories         : 1,639 products\n",
      "   8. toys                          : 1,411 products\n",
      "   9. watches_gifts                 : 1,329 products\n",
      "  10. telephony                     : 1,134 products\n",
      "  11. baby                          :  919 products\n",
      "  12. perfumery                     :  868 products\n",
      "  13. fashion_bags_accessories      :  849 products\n",
      "  14. stationery                    :  849 products\n",
      "  15. cool_stuff                    :  789 products\n",
      "\n",
      "‚ö†Ô∏è  Products without category translation: 623\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PRODUCT CATEGORIES ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüè∑Ô∏è PRODUCT CATEGORIES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Merge products with category translation\n",
    "products_with_category = products.merge(\n",
    "    category_translation,\n",
    "    on='product_category_name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Top categories by product count\n",
    "top_categories = products_with_category['product_category_name_english'].value_counts().head(15)\n",
    "\n",
    "print(f\"\\nüìä Top 15 Product Categories by Product Count:\")\n",
    "for idx, (category, count) in enumerate(top_categories.items(), 1):\n",
    "    print(f\"  {idx:2d}. {str(category):30s}: {count:4,} products\")\n",
    "\n",
    "# Products without category\n",
    "no_category = products_with_category['product_category_name_english'].isna().sum()\n",
    "print(f\"\\n‚ö†Ô∏è  Products without category translation: {no_category:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e12ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí∞ SALES & REVENUE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìà Overall Metrics:\n",
      "  Total Revenue:     R$ 13,591,643.70\n",
      "  Total Freight:     R$ 2,251,909.54\n",
      "  Combined Total:    R$ 15,843,553.24\n",
      "  Total Items Sold:  112,650\n",
      "  Average Item Price: R$ 120.65\n",
      "\n",
      "üõí Order Value Metrics:\n",
      "  Average Order Value (AOV): R$ 137.75\n",
      "  Median Order Value:        R$ 86.90\n",
      "  Min Order Value:           R$ 0.85\n",
      "  Max Order Value:           R$ 13440.00\n",
      "\n",
      "üì¶ Items per Order:\n",
      "  Average items per order: 1.14\n",
      "  Median items per order:  1\n",
      "  Max items in one order:  21\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SALES & REVENUE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüí∞ SALES & REVENUE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Merge order items with orders to get dates\n",
    "order_items_with_dates = order_items.merge(\n",
    "    orders[['order_id', 'order_purchase_timestamp', 'order_status']],\n",
    "    on='order_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate total revenue\n",
    "total_revenue = order_items_with_dates['price'].sum()\n",
    "total_freight = order_items_with_dates['freight_value'].sum()\n",
    "total_items = len(order_items_with_dates)\n",
    "\n",
    "print(f\"\\nüìà Overall Metrics:\")\n",
    "print(f\"  Total Revenue:     R$ {total_revenue:,.2f}\")\n",
    "print(f\"  Total Freight:     R$ {total_freight:,.2f}\")\n",
    "print(f\"  Combined Total:    R$ {total_revenue + total_freight:,.2f}\")\n",
    "print(f\"  Total Items Sold:  {total_items:,}\")\n",
    "print(f\"  Average Item Price: R$ {total_revenue / total_items:.2f}\")\n",
    "\n",
    "# Average Order Value (AOV)\n",
    "revenue_by_order = order_items_with_dates.groupby('order_id')['price'].sum()\n",
    "aov = revenue_by_order.mean()\n",
    "median_order = revenue_by_order.median()\n",
    "\n",
    "print(f\"\\nüõí Order Value Metrics:\")\n",
    "print(f\"  Average Order Value (AOV): R$ {aov:.2f}\")\n",
    "print(f\"  Median Order Value:        R$ {median_order:.2f}\")\n",
    "print(f\"  Min Order Value:           R$ {revenue_by_order.min():.2f}\")\n",
    "print(f\"  Max Order Value:           R$ {revenue_by_order.max():.2f}\")\n",
    "\n",
    "# Items per order\n",
    "items_per_order = order_items_with_dates.groupby('order_id').size()\n",
    "print(f\"\\nüì¶ Items per Order:\")\n",
    "print(f\"  Average items per order: {items_per_order.mean():.2f}\")\n",
    "print(f\"  Median items per order:  {items_per_order.median():.0f}\")\n",
    "print(f\"  Max items in one order:  {items_per_order.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a47754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí≥ PAYMENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä Payment Methods Distribution:\n",
      "  credit_card    : 76,795 (73.92%) - Avg: R$ 163.32\n",
      "  boleto         : 19,784 (19.04%) - Avg: R$ 145.03\n",
      "  voucher        :  5,775 ( 5.56%) - Avg: R$ 65.70\n",
      "  debit_card     :  1,529 ( 1.47%) - Avg: R$ 142.57\n",
      "  not_defined    :      3 ( 0.00%) - Avg: R$ 0.00\n",
      "\n",
      "üìä Payment Installments (Top 10):\n",
      "   0 installments:      2 ( 0.00%)\n",
      "   1 installments: 52,546 (50.58%)\n",
      "   2 installments: 12,413 (11.95%)\n",
      "   3 installments: 10,461 (10.07%)\n",
      "   4 installments:  7,098 ( 6.83%)\n",
      "   5 installments:  5,239 ( 5.04%)\n",
      "   6 installments:  3,920 ( 3.77%)\n",
      "   7 installments:  1,626 ( 1.57%)\n",
      "   8 installments:  4,268 ( 4.11%)\n",
      "   9 installments:    644 ( 0.62%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PAYMENT ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüí≥ PAYMENT ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Payment type distribution\n",
    "payment_types = payments['payment_type'].value_counts()\n",
    "payment_pct = payments['payment_type'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nüìä Payment Methods Distribution:\")\n",
    "for ptype, count in payment_types.items():\n",
    "    pct = payment_pct[ptype]\n",
    "    avg_value = payments[payments['payment_type'] == ptype]['payment_value'].mean()\n",
    "    print(f\"  {ptype:15s}: {count:6,} ({pct:5.2f}%) - Avg: R$ {avg_value:,.2f}\")\n",
    "\n",
    "# Installments analysis\n",
    "installment_dist = payments['payment_installments'].value_counts().sort_index()\n",
    "print(f\"\\nüìä Payment Installments (Top 10):\")\n",
    "for installments, count in installment_dist.head(10).items():\n",
    "    pct = (count / len(payments)) * 100\n",
    "    print(f\"  {installments:2d} installments: {count:6,} ({pct:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b459a1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üó∫Ô∏è GEOGRAPHY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìç Top 10 Customer Cities:\n",
      "   1. sao paulo                : 15,540 (15.63%)\n",
      "   2. rio de janeiro           : 6,882 (6.92%)\n",
      "   3. belo horizonte           : 2,773 (2.79%)\n",
      "   4. brasilia                 : 2,131 (2.14%)\n",
      "   5. curitiba                 : 1,521 (1.53%)\n",
      "   6. campinas                 : 1,444 (1.45%)\n",
      "   7. porto alegre             : 1,379 (1.39%)\n",
      "   8. salvador                 : 1,245 (1.25%)\n",
      "   9. guarulhos                : 1,189 (1.20%)\n",
      "  10. sao bernardo do campo    :   938 (0.94%)\n",
      "\n",
      "üìç Top 10 Customer States:\n",
      "   1. SP   : 41,746 (41.98%)\n",
      "   2. RJ   : 12,852 (12.92%)\n",
      "   3. MG   : 11,635 (11.70%)\n",
      "   4. RS   : 5,466 (5.50%)\n",
      "   5. PR   : 5,045 (5.07%)\n",
      "   6. SC   : 3,637 (3.66%)\n",
      "   7. BA   : 3,380 (3.40%)\n",
      "   8. DF   : 2,140 (2.15%)\n",
      "   9. ES   : 2,033 (2.04%)\n",
      "  10. GO   : 2,020 (2.03%)\n",
      "\n",
      "üìç Top 10 Seller States:\n",
      "   1. SP   : 1,849 (59.74%)\n",
      "   2. PR   :   349 (11.28%)\n",
      "   3. MG   :   244 (7.88%)\n",
      "   4. SC   :   190 (6.14%)\n",
      "   5. RJ   :   171 (5.53%)\n",
      "   6. RS   :   129 (4.17%)\n",
      "   7. GO   :    40 (1.29%)\n",
      "   8. DF   :    30 (0.97%)\n",
      "   9. ES   :    23 (0.74%)\n",
      "  10. BA   :    19 (0.61%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# GEOGRAPHY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüó∫Ô∏è GEOGRAPHY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Top customer cities\n",
    "top_customer_cities = customers['customer_city'].value_counts().head(10)\n",
    "print(\"\\nüìç Top 10 Customer Cities:\")\n",
    "for idx, (city, count) in enumerate(top_customer_cities.items(), 1):\n",
    "    pct = (count / len(customers)) * 100\n",
    "    print(f\"  {idx:2d}. {city:25s}: {count:5,} ({pct:4.2f}%)\")\n",
    "\n",
    "# Top customer states\n",
    "top_customer_states = customers['customer_state'].value_counts().head(10)\n",
    "print(\"\\nüìç Top 10 Customer States:\")\n",
    "for idx, (state, count) in enumerate(top_customer_states.items(), 1):\n",
    "    pct = (count / len(customers)) * 100\n",
    "    print(f\"  {idx:2d}. {state:5s}: {count:5,} ({pct:4.2f}%)\")\n",
    "\n",
    "# Sellers distribution\n",
    "top_seller_states = sellers['seller_state'].value_counts().head(10)\n",
    "print(\"\\nüìç Top 10 Seller States:\")\n",
    "for idx, (state, count) in enumerate(top_seller_states.items(), 1):\n",
    "    pct = (count / len(sellers)) * 100\n",
    "    print(f\"  {idx:2d}. {state:5s}: {count:5,} ({pct:4.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f789de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚≠ê CUSTOMER REVIEW ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä Review Score Distribution:\n",
      "  ‚≠ê          (1): 11,424 (11.51%)\n",
      "  ‚≠ê‚≠ê         (2):  3,151 ( 3.18%)\n",
      "  ‚≠ê‚≠ê‚≠ê        (3):  8,179 ( 8.24%)\n",
      "  ‚≠ê‚≠ê‚≠ê‚≠ê       (4): 19,142 (19.29%)\n",
      "  ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê      (5): 57,328 (57.78%)\n",
      "\n",
      "üìä Average Review Score: 4.09 / 5.0\n",
      "\n",
      "üí¨ Reviews with comments: 40,977 (41.30%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CUSTOMER REVIEW ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n‚≠ê CUSTOMER REVIEW ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Review score distribution\n",
    "review_scores = reviews['review_score'].value_counts().sort_index()\n",
    "print(\"\\nüìä Review Score Distribution:\")\n",
    "for score, count in review_scores.items():\n",
    "    pct = (count / len(reviews)) * 100\n",
    "    stars = \"‚≠ê\" * int(score)\n",
    "    print(f\"  {stars:10s} ({score}): {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "avg_score = reviews['review_score'].mean()\n",
    "print(f\"\\nüìä Average Review Score: {avg_score:.2f} / 5.0\")\n",
    "\n",
    "# Reviews with comments\n",
    "reviews_with_comments = reviews['review_comment_message'].notna().sum()\n",
    "comment_rate = (reviews_with_comments / len(reviews)) * 100\n",
    "print(f\"\\nüí¨ Reviews with comments: {reviews_with_comments:,} ({comment_rate:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe23432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó DATA RELATIONSHIPS & QUALITY\n",
      "================================================================================\n",
      "\n",
      "üìä Key Relationships:\n",
      "  Unique Orders:        99,441\n",
      "  Unique Customers:     99,441\n",
      "  Unique Products:      32,951\n",
      "  Unique Sellers:       3,095\n",
      "\n",
      "üìä Customer Behavior:\n",
      "  Customers with 1 order:    99,441 (100.00%)\n",
      "  Customers with 2+ orders:  0 (0.00%)\n",
      "  Max orders by one customer: 1\n",
      "\n",
      "‚úÖ Data Quality Summary:\n",
      "  Orders with missing approved date:       160\n",
      "  Orders with missing delivery date:       2,965\n",
      "  Products without category:                610\n",
      "  Orders without reviews:                   217\n",
      "\n",
      "üéØ DATASET IS READY FOR PIPELINE DEVELOPMENT!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA RELATIONSHIPS & QUALITY CHECK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîó DATA RELATIONSHIPS & QUALITY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Key Relationships:\")\n",
    "print(f\"  Unique Orders:        {orders['order_id'].nunique():,}\")\n",
    "print(f\"  Unique Customers:     {orders['customer_id'].nunique():,}\")\n",
    "print(f\"  Unique Products:      {order_items['product_id'].nunique():,}\")\n",
    "print(f\"  Unique Sellers:       {order_items['seller_id'].nunique():,}\")\n",
    "\n",
    "print(\"\\nüìä Customer Behavior:\")\n",
    "orders_per_customer = orders.groupby('customer_id').size()\n",
    "print(f\"  Customers with 1 order:    {(orders_per_customer == 1).sum():,} ({(orders_per_customer == 1).sum() / len(orders_per_customer) * 100:.2f}%)\")\n",
    "print(f\"  Customers with 2+ orders:  {(orders_per_customer >= 2).sum():,} ({(orders_per_customer >= 2).sum() / len(orders_per_customer) * 100:.2f}%)\")\n",
    "print(f\"  Max orders by one customer: {orders_per_customer.max()}\")\n",
    "\n",
    "print(\"\\n‚úÖ Data Quality Summary:\")\n",
    "print(f\"  Orders with missing approved date:       {orders['order_approved_at'].isna().sum():,}\")\n",
    "print(f\"  Orders with missing delivery date:       {orders['order_delivered_customer_date'].isna().sum():,}\")\n",
    "print(f\"  Products without category:                {products['product_category_name'].isna().sum():,}\")\n",
    "print(f\"  Orders without reviews:                   {len(orders) - len(reviews):,}\")\n",
    "\n",
    "print(\"\\nüéØ DATASET IS READY FOR PIPELINE DEVELOPMENT!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c039a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ KEY TAKEAWAYS FOR PIPELINE DEVELOPMENT\n",
      "================================================================================\n",
      "\n",
      "1. DATA VOLUME: 1.5M+ records across 9 tables - substantial dataset\n",
      "2. TIME RANGE: ~2 years of data (2016-2018) - good for time series analysis\n",
      "3. DATA QUALITY: 97% completion rate, minor missing values manageable\n",
      "4. STAR SCHEMA READY: Clear fact (orders) and dimension tables (customers, products, sellers)\n",
      "5. CUSTOMER RETENTION: 0% repeat rate - major business problem to analyze!\n",
      "6. GEOGRAPHY: Highly concentrated in S√£o Paulo - geographic analysis potential\n",
      "7. REVIEWS: Rich sentiment data with 41% having text comments - NLP opportunity\n",
      "8. PAYMENTS: Diverse methods and installment plans - financial analysis ready\n",
      "9. DELIVERY: Average 12 days - operational metrics to track\n",
      "10. CATEGORIES: 71 product categories - good for segmentation\n",
      "\n",
      "NEXT STEPS:\n",
      "‚úÖ Data exploration complete\n",
      "‚û°Ô∏è Set up PostgreSQL database (Docker)\n",
      "‚û°Ô∏è Design star schema for data warehouse\n",
      "‚û°Ô∏è Build ETL pipeline to load data\n",
      "‚û°Ô∏è Set up real-time streaming simulation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# KEY TAKEAWAYS FOR PIPELINE DEVELOPMENT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ KEY TAKEAWAYS FOR PIPELINE DEVELOPMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "takeaways = \"\"\"\n",
    "1. DATA VOLUME: 1.5M+ records across 9 tables - substantial dataset\n",
    "2. TIME RANGE: ~2 years of data (2016-2018) - good for time series analysis\n",
    "3. DATA QUALITY: 97% completion rate, minor missing values manageable\n",
    "4. STAR SCHEMA READY: Clear fact (orders) and dimension tables (customers, products, sellers)\n",
    "5. CUSTOMER RETENTION: 0% repeat rate - major business problem to analyze!\n",
    "6. GEOGRAPHY: Highly concentrated in S√£o Paulo - geographic analysis potential\n",
    "7. REVIEWS: Rich sentiment data with 41% having text comments - NLP opportunity\n",
    "8. PAYMENTS: Diverse methods and installment plans - financial analysis ready\n",
    "9. DELIVERY: Average 12 days - operational metrics to track\n",
    "10. CATEGORIES: 71 product categories - good for segmentation\n",
    "\n",
    "NEXT STEPS:\n",
    "‚úÖ Data exploration complete\n",
    "‚û°Ô∏è Set up PostgreSQL database (Docker)\n",
    "‚û°Ô∏è Design star schema for data warehouse\n",
    "‚û°Ô∏è Build ETL pipeline to load data\n",
    "‚û°Ô∏è Set up real-time streaming simulation\n",
    "\"\"\"\n",
    "\n",
    "print(takeaways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f052ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
